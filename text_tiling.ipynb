{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "We will implement a text tiling algorithm to segment the text into coherent sections. The algorithm is based on the following steps:\n",
    "1. Split the text in sentences\n",
    "2. Clean the sentences by removing stopwords and punctuation\n",
    "3. Find frequency table for the words in the sentences\n",
    "    - The x-axis is the sentence number\n",
    "    - The y-axis is each word\n",
    "    - Each cell is the frequency of the word in the sentence\n",
    "4. Initialize blocks of text with a fixed size\n",
    "5. Iterate until no change in the blocks\n",
    "    - Calculate the intra-group cohesion for each block\n",
    "    - Find blocks of text where the topic changes (the cohesion drops in these blocks)\n",
    "    - Move block boundaries to the topic change points\n",
    "6. Return the blocks of text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2128fb72ea87456"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "from string import punctuation\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:45:47.484283Z",
     "start_time": "2024-04-04T14:45:47.473591Z"
    }
   },
   "id": "5dd6f9034c1ec2a7",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, text: str, words: List[str]):\n",
    "        self.text = text\n",
    "        self.words = words\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:45:47.702706Z",
     "start_time": "2024-04-04T14:45:47.685443Z"
    }
   },
   "id": "ffba7c5a7aaf9b22",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# retrieve text from res/mixed_texts.txt\n",
    "with open('res/mixed_texts.txt', 'r') as file:\n",
    "    raw_text = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:45:47.779956Z",
     "start_time": "2024-04-04T14:45:47.714850Z"
    }
   },
   "id": "ea8ccdbbb0b10862",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[In order to get to punch his badge at 08:30, 16 years before Fantozzi began setting alarm clock at 06:15.,\n Today, after continuous experiments and improvements, he manage to set it at 07:51: the limit of humanly possibilities.,\n Everything is calculated on the edge of seconds: 5 seconds to regain consciousness; 4 seconds to overcome impact of seeing his wife, and 6 more seconds to ask himself -as always with any plausible answer- whatever pushed him to marry that kind of curious pet; 3 seconds to drink Mrs Fantozzi's coffee: 3000 Fahreneit Degrees!,\n From 8 to 10 seconds to cool down his burned tongue... 2.5 seconds to kiss his daughter Mariangela; brioche and Latte meanwhile hair brushing, brushing coffee-flavoured teeth with minty toothpaste, resulting in an instantaneous bowel movement... all of this performed in 6 seconds, a European Record!,\n He still has a 3-minute fortune to get dressed and run to the bus stop to catch the 08:01 bus.]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> List[Sentence]:\n",
    "    \"\"\"\n",
    "    Preprocess the text by splitting it into sentences and removing unimportant words.\n",
    "    :param text: the text to be preprocessed\n",
    "    :return: a list of relevant words extracted from text\n",
    "    \"\"\"\n",
    "    # get the list of stopwords\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    \n",
    "    sentence_list: List[Sentence] = []\n",
    "\n",
    "    # split the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # remove stopwords and punctuation\n",
    "    for sentence in sentences:\n",
    "        relevant_words = [word.lower() for word in nltk.word_tokenize(sentence) if word.lower() not in stopwords_list and word not in punctuation]\n",
    "        sentence_list.append(Sentence(sentence, relevant_words))\n",
    "        \n",
    "    return sentence_list\n",
    "\n",
    "preprocess_text(raw_text)[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:45:47.916177Z",
     "start_time": "2024-04-04T14:45:47.844526Z"
    }
   },
   "id": "d4fb0e2b6091c421",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # create a frequency table for the words in the sentences\n",
    "# frequency_table = []\n",
    "# \n",
    "# for sentence in cleaned_sentences:\n",
    "#     # get counts of word frequency in the sentence\n",
    "#     frequency = Counter(sentence)\n",
    "#     frequency_table.append(frequency)\n",
    "#     \n",
    "# # print the frequency table for the first 5 sentences\n",
    "# frequency_table[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:45:47.994101Z",
     "start_time": "2024-04-04T14:45:47.965184Z"
    }
   },
   "id": "74007fabc282ffa8",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1:\n",
      "In order to get to punch his badge at 08:30, 16 years before Fantozzi began setting alarm clock at 06:15.\n",
      "Today, after continuous experiments and improvements, he manage to set it at 07:51: the limit of humanly possibilities.\n",
      "Everything is calculated on the edge of seconds: 5 seconds to regain consciousness; 4 seconds to overcome impact of seeing his wife, and 6 more seconds to ask himself -as always with any plausible answer- whatever pushed him to marry that kind of curious pet; 3 seconds to drink Mrs Fantozzi's coffee: 3000 Fahreneit Degrees!\n",
      "From 8 to 10 seconds to cool down his burned tongue... 2.5 seconds to kiss his daughter Mariangela; brioche and Latte meanwhile hair brushing, brushing coffee-flavoured teeth with minty toothpaste, resulting in an instantaneous bowel movement... all of this performed in 6 seconds, a European Record!\n",
      "He still has a 3-minute fortune to get dressed and run to the bus stop to catch the 08:01 bus.\n",
      "Of course, this is possible without tragic unforeseen circumstances.\n",
      "The Resurrection of Jesus Christ is the foundation of the Christian faith.\n",
      "Without the resurrection, the belief in God's saving grace through Jesus is destroyed.\n",
      "\n",
      "Block 2:\n",
      "When Jesus rose from the dead, he confirmed his identity as the Son of God and his work of atonement, redemption, reconciliation, and salvation.\n",
      "The Resurrection was a literal, physical raising of Jesus body from the dead.\n",
      "Jesus was arrested, tried, and found guilty of claiming to be a king.\n",
      "His body was hung on a cross between two thieves.\n",
      "After his death, Jesus body was wrapped in linen cloth and placed in a tomb with a large stone rolled across the opening.\n",
      "On the third day, an early Sunday morning, Mary Magdalene and another Mary came to the tomb and found it empty.\n",
      "Sitting on the rolled-away stone was an angel of the Lord who told them not to be afraid because Jesus had risen.\n",
      "As the women left to tell the disciples, Jesus Christ met them and showed them his nail-pierced hands.\n",
      "\n",
      "Block 3:\n",
      "The Old and the New Testaments speak of the truth of Jesus being raised from death - Jesus testified of his resurrection before He died on the cross, and his disciples witnessed his body after the resurrection.\n",
      "Below are the Bible verses and Scriptures that both prophesize the resurrection of Jesus and testify of the reality of the resurrected body of Christ.\n",
      "A spectre is haunting Europe -- the spectre of communism.\n",
      "All the powers of old Europe have entered into a holy alliance to exorcise this spectre: Pope and Tsar, Metternich and Guizot, French Radicals and German police-spies.\n",
      "Where is the party in opposition that has not been decried as communistic by its opponents in power?\n",
      "Where is the opposition that has not hurled back the branding reproach of communism, against the more advanced opposition parties, as well as against its reactionary adversaries?\n",
      "Two things result from this fact: Communism is already acknowledged by all European powers to be itself a power, It is high time that Communists should openly, in the face of the whole world, publish their views, their aims, their tendencies, and meet this nursery tale of the  spectre of communism with a manifesto of the party itself.\n",
      "To this end, Communists of various nationalities have assembled in London and sketched the following manifesto, to be published in the English, French, German, Italian, Flemish and Danish languages.\n"
     ]
    }
   ],
   "source": [
    "def initialize_blocks(sentences: List[Sentence], num_blocks: int) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Initialize blocks of text with a fixed size. Each block will contain a subset of the text.\n",
    "    :param sentences: the list of sentences to be split into blocks\n",
    "    :param num_blocks: the number of blocks to initialize\n",
    "    :return: a list of blocks of text\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    block_size = len(sentences) // num_blocks\n",
    "    \n",
    "    for i in range(num_blocks):\n",
    "        start = i * block_size\n",
    "        end = (i + 1) * block_size\n",
    "        block = sentences[start:end]\n",
    "        blocks.append(block)\n",
    "        \n",
    "    return blocks\n",
    "\n",
    "# Example usage\n",
    "# sentences = preprocess_text(raw_text)\n",
    "# blocks = initialize_blocks(sentences, 3)\n",
    "# for i, block in enumerate(blocks):\n",
    "#     print(f\"Block {i+1}:\")\n",
    "#     for sentence in block:\n",
    "#         print(sentence)\n",
    "#     print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:45:48.207413Z",
     "start_time": "2024-04-04T14:45:48.140171Z"
    }
   },
   "id": "531ef585d4d1f02",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1414314788.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[50], line 27\u001B[1;36m\u001B[0m\n\u001B[1;33m    for\u001B[0m\n\u001B[1;37m       ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def text_tiling(text: str, num_blocks: int, max_block_size: int) -> List[List[Sentence]]:\n",
    "    \"\"\"\n",
    "    Segment the text into coherent sections using the text tiling algorithm.\n",
    "    1. Preprocess the text so that we have a list of Sentence objects\n",
    "    2. Initialize blocks (lists of Sentences) with a fixed size\n",
    "    3. Iterate until no change in the blocks\n",
    "        - Calculate the intra-block cohesion for each Sentence\n",
    "        - Find Sentences where the topic changes (the cohesion is lower than the one of the adjacent Sentences)\n",
    "        - Move block boundaries to the topic change points\n",
    "    4. Return the blocks of text\n",
    "    :param text: the text to be segmented\n",
    "    :param num_blocks: the number of blocks to split the text into\n",
    "    :param max_block_size: the maximum number of Sentences in each block\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # Preprocess the text\n",
    "    sentences = preprocess_text(text)\n",
    "    \n",
    "    # Initialize blocks of text\n",
    "    blocks = initialize_blocks(words, num_blocks)\n",
    "    \n",
    "    n_times_no_change = 0\n",
    "    # Iterate until no change in the blocks\n",
    "    while n_times_no_change < 3:\n",
    "        # Calculate the intra-group cohesion for each block\n",
    "        cohesion_scores: List[float] = []\n",
    "        for block in blocks:\n",
    "            # Calculate the cohesion score for the block\n",
    "            block_cohesion_scores = calculate_intra_block_cohesion(block)\n",
    "            cohesion_scores + block_cohesion_scores\n",
    "            \n",
    "        # Find blocks of text where the topic changes\n",
    "        change_points = find_topic_change_points(cohesion_scores)\n",
    "        \n",
    "        # Move block boundaries to the topic change points\n",
    "        new_blocks = move_block_boundaries(blocks, change_points, max_block_size)\n",
    "        \n",
    "        # Check if the blocks have changed\n",
    "        if new_blocks == blocks:\n",
    "            n_times_no_change += 1\n",
    "        else:\n",
    "            n_times_no_change = 0\n",
    "            blocks = new_blocks\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:45:48.390909Z",
     "start_time": "2024-04-04T14:45:48.352191Z"
    }
   },
   "id": "a93feb0ee7c6c9a6",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def calculate_intra_doc_cohesion(text: str) -> List[float]:\n",
    "#     # Preprocess the text\n",
    "#     sentences = preprocess(text)\n",
    "#     \n",
    "#     # TF-IDF vectorization\n",
    "#     vectorizer = TfidfVectorizer()\n",
    "#     tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "#     \n",
    "#     # Calculate cosine similarity between adjacent sentences\n",
    "#     similarity_scores = []\n",
    "#     for i in range(len(sentences) - 1):\n",
    "#         sim_score = cosine_similarity(tfidf_matrix[i], tfidf_matrix[i+1])\n",
    "#         similarity_scores.append(sim_score[0][0])\n",
    "#     \n",
    "#     # Aggregate similarity scores\n",
    "#     cohesion_score = sum(similarity_scores) / len(similarity_scores)\n",
    "#     \n",
    "#     return cohesion_score\n",
    "# \n",
    "# # Example usage\n",
    "# text = \"This is a sample text. It demonstrates how to calculate intra-document cohesion between sentences. Intra-document cohesion is important for understanding the coherence of a document.\"\n",
    "# cohesion_score = calculate_intra_doc_cohesion(text)\n",
    "# print(\"Intra-document cohesion score:\", cohesion_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:45:48.499840Z",
     "start_time": "2024-04-04T14:45:48.475483Z"
    }
   },
   "id": "2b8168d18ff335ec",
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
