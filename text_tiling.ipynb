{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "We will implement a text tiling algorithm to segment the text into coherent sections. The algorithm is based on the following steps:\n",
    "1. Split the text in sentences\n",
    "2. Clean the sentences by removing stopwords and punctuation\n",
    "3. Find frequency table for the words in the sentences\n",
    "    - The x-axis is the sentence number\n",
    "    - The y-axis is each word\n",
    "    - Each cell is the frequency of the word in the sentence\n",
    "4. Initialize blocks of text with a fixed size\n",
    "5. Iterate until no change in the blocks\n",
    "    - Calculate the intra-group cohesion for each block\n",
    "    - Find blocks of text where the topic changes (the cohesion drops in these blocks)\n",
    "    - Move block boundaries to the topic change points\n",
    "6. Return the blocks of text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2128fb72ea87456"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "from string import punctuation\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:55.308813Z",
     "start_time": "2024-04-08T10:06:55.282604Z"
    }
   },
   "id": "5dd6f9034c1ec2a7",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, text: str, words: List[str]):\n",
    "        self.text = text\n",
    "        self.words = words\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return self.text == other.text\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.text\n",
    "    \n",
    "class Block:\n",
    "    def __init__(self, sentences: List[Sentence]):\n",
    "        self.sentences = sentences\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if len(self.sentences) != len(other.sentences):\n",
    "            return False\n",
    "        # true if all sentences equal\n",
    "        return all([self.sentences[i] == other.sentences[i] for i in range(len(self.sentences))])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \" \".join([sentence.text for sentence in self.sentences])\n",
    "    \n",
    "    def get_string_sentences(self) -> List[str]:\n",
    "        return [\" \".join(sentence.words) for sentence in self.sentences]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:55.371978Z",
     "start_time": "2024-04-08T10:06:55.349801Z"
    }
   },
   "id": "ffba7c5a7aaf9b22",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# retrieve text from res/mixed_texts.txt\n",
    "with open('res/mixed_texts.txt', 'r') as file:\n",
    "    raw_text = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:55.463850Z",
     "start_time": "2024-04-08T10:06:55.449163Z"
    }
   },
   "id": "ea8ccdbbb0b10862",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[All the powers of old Europe have entered into a holy alliance to exorcise this spectre: Pope and Tsar, Metternich and Guizot, French Radicals and German police-spies.,\n Where is the party in opposition that has not been decried as communistic by its opponents in power?,\n Where is the opposition that has not hurled back the branding reproach of communism, against the more advanced opposition parties, as well as against its reactionary adversaries?,\n Two things result from this fact: Communism is already acknowledged by all European powers to be itself a power, It is high time that Communists should openly, in the face of the whole world, publish their views, their aims, their tendencies, and meet this nursery tale of the  spectre of communism with a manifesto of the party itself.,\n To this end, Communists of various nationalities have assembled in London and sketched the following manifesto, to be published in the English, French, German, Italian, Flemish and Danish languages.]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> List[Sentence]:\n",
    "    \"\"\"\n",
    "    Preprocess the text by splitting it into sentences and removing unimportant words.\n",
    "    :param text: the text to be preprocessed\n",
    "    :return: a list of relevant words extracted from text\n",
    "    \"\"\"\n",
    "    # get the list of stopwords\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    \n",
    "    sentence_list: List[Sentence] = []\n",
    "\n",
    "    # split the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # remove stopwords and punctuation\n",
    "    for sentence in sentences:\n",
    "        relevant_words = [word.lower() for word in nltk.word_tokenize(sentence) if word.lower() not in stopwords_list and word not in punctuation]\n",
    "        sentence_list.append(Sentence(sentence, relevant_words))\n",
    "        \n",
    "    return sentence_list\n",
    "\n",
    "preprocess_text(raw_text)[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:11:16.904317Z",
     "start_time": "2024-04-08T10:11:16.856456Z"
    }
   },
   "id": "d4fb0e2b6091c421",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # create a frequency table for the words in the sentences\n",
    "# frequency_table = []\n",
    "# \n",
    "# for sentence in cleaned_sentences:\n",
    "#     # get counts of word frequency in the sentence\n",
    "#     frequency = Counter(sentence)\n",
    "#     frequency_table.append(frequency)\n",
    "#     \n",
    "# # print the frequency table for the first 5 sentences\n",
    "# frequency_table[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:55.618391Z",
     "start_time": "2024-04-08T10:06:55.601765Z"
    }
   },
   "id": "74007fabc282ffa8",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def initialize_blocks(sentences: List[Sentence], num_blocks: int) -> List[Block]:\n",
    "    \"\"\"\n",
    "    Initialize blocks of text with a fixed size. Each block will contain a subset of the text.\n",
    "    :param sentences: the list of sentences to be split into blocks\n",
    "    :param num_blocks: the number of blocks to initialize\n",
    "    :return: a list of blocks of text\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    block_size = len(sentences) // num_blocks\n",
    "    \n",
    "    for i in range(num_blocks):\n",
    "        start = i * block_size\n",
    "        end = (i + 1) * block_size\n",
    "        block = Block(sentences[start:end])\n",
    "        blocks.append(block)\n",
    "        \n",
    "    return blocks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:55.788287Z",
     "start_time": "2024-04-08T10:06:55.763416Z"
    }
   },
   "id": "531ef585d4d1f02",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# sentences = preprocess_text(raw_text)\n",
    "# blocks = initialize_blocks(sentences, 3)\n",
    "# for i, block in enumerate(blocks):\n",
    "#     print(f\"Block {i+1}:\")\n",
    "#     for sentence in block:\n",
    "#         print(sentence)\n",
    "#     print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:55.896133Z",
     "start_time": "2024-04-08T10:06:55.885578Z"
    }
   },
   "id": "84eed9b69533d3be"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_intra_group_cohesion(sentences: List[Sentence]) -> List[float]:\n",
    "\n",
    "    # TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([\" \".join(sentence.words) for sentence in sentences])\n",
    "\n",
    "    # Calculate cosine similarity between adjacent sentences\n",
    "    cohesion_scores = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        sim_score = cosine_similarity(tfidf_matrix[i], tfidf_matrix[i+1])\n",
    "        cohesion_scores.append(sim_score[0][0])\n",
    "    \n",
    "    return cohesion_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:56.035786Z",
     "start_time": "2024-04-08T10:06:56.009515Z"
    }
   },
   "id": "200db4fe52615fdc",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intra-document cohesion score: [0.0, 0.4179779031144455]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"This is a sample text. It demonstrates how to calculate intra-document cohesion between sentences. Intra-document cohesion is important for understanding the coherence of a document.\"\n",
    "sentences = preprocess_text(text)\n",
    "cohesion_score = calculate_intra_group_cohesion(sentences)\n",
    "print(\"Intra-document cohesion score:\", cohesion_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:56.097672Z",
     "start_time": "2024-04-08T10:06:56.064649Z"
    }
   },
   "id": "bbca333e34113950"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def find_topic_change_points(cohesion_scores: List[float], num_splits: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Identify the indices for topic change points based on the largest drops in cohesion scores.\n",
    "    :param cohesion_scores: List of cohesion scores between sentences.\n",
    "    :param num_splits: Number of splits (topic changes) to make.\n",
    "    :return: Indices of sentences before which there's a potential topic change.\n",
    "    \"\"\"\n",
    "    # Calculate drops in cohesion scores\n",
    "    drops = [cohesion_scores[i-1] - cohesion_scores[i] + cohesion_scores[i+1] for i in range(1, len(cohesion_scores)-1)]\n",
    "    \n",
    "    # drop indexes sorted in ascending order\n",
    "    drops_indexes_sorted_asc = np.argsort(drops)\n",
    "    # deepest num_splits drop indexes, sorted in ascending order\n",
    "    deepest_drops_indexes_sorted_asc = drops_indexes_sorted_asc[-num_splits:]\n",
    "    # sort the deepest drops indexes in ascending order\n",
    "    change_points = np.sort(deepest_drops_indexes_sorted_asc)\n",
    "    \n",
    "    return [cp + 1 for cp in change_points]  # Adjust indices to point to sentences after the drops."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:56.144865Z",
     "start_time": "2024-04-08T10:06:56.122161Z"
    }
   },
   "id": "b796c13d03c5878f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def move_block_boundaries(sentences: List[Sentence], change_points: List[int]) -> List[Block]:\n",
    "    \"\"\"\n",
    "    Create new blocks based on the identified topic change points.\n",
    "    :param sentences: List of all sentences.\n",
    "    :param change_points: Indices of sentences indicating topic changes.\n",
    "    :return: New list of blocks adjusted for topic changes.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    # Index of the first sentence in the currently iterated block\n",
    "    start_index = 0\n",
    "\n",
    "    for cp in change_points:\n",
    "        # Calculate temporary block size\n",
    "        blocks.append(Block(sentences[start_index:cp]))\n",
    "        start_index = cp\n",
    "    \n",
    "    return blocks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:06:56.238850Z",
     "start_time": "2024-04-08T10:06:56.212722Z"
    }
   },
   "id": "818113419fe825b9",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def text_tiling(text: str, num_blocks: int, max_block_size: int) -> List[Block]:\n",
    "    \"\"\"\n",
    "    Segment the text into coherent sections using the text tiling algorithm.\n",
    "    1. Preprocess the text so that we have a list of Sentence objects\n",
    "    2. Initialize Blocks with a fixed size\n",
    "    3. Iterate until no change in the Blocks\n",
    "        - Calculate the intra-block cohesion for each Sentence\n",
    "        - Find Sentences where the topic changes (the cohesion is lower than the one of the adjacent Sentences)\n",
    "        - Move Block boundaries to the topic change points\n",
    "    4. Return the Blocks\n",
    "    :param text: the text to be segmented\n",
    "    :param num_blocks: the number of Blocks to split the text into\n",
    "    :param max_block_size: the maximum number of Sentences in each Block\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocess the text\n",
    "    sentences: List[Sentence] = preprocess_text(text)\n",
    "    \n",
    "    # Initialize blocks of text\n",
    "    blocks: List[Block] = initialize_blocks(sentences, num_blocks)\n",
    "    \n",
    "    n_times_no_change = 0\n",
    "    remaining_iterations = 100\n",
    "    # Iterate until no change in the blocks\n",
    "    while n_times_no_change < 3 or remaining_iterations > 0:\n",
    "        # Calculate the intra-group cohesion for each block\n",
    "        \n",
    "        cohesion_scores: List[float] = calculate_intra_group_cohesion(sentences)\n",
    "        # print(cohesion_scores)\n",
    "        \n",
    "        # for block in blocks:\n",
    "        #     # Calculate the cohesion score for the block\n",
    "        #     block_cohesion_scores = calculate_intra_group_cohesion(block)\n",
    "        #     print(block_cohesion_scores)\n",
    "        #     cohesion_scores = cohesion_scores + block_cohesion_scores\n",
    "        \n",
    "        # Find blocks of text where the topic changes\n",
    "        change_points = find_topic_change_points(cohesion_scores, num_blocks)\n",
    "        \n",
    "        # Move block boundaries to the topic change points\n",
    "        new_blocks = move_block_boundaries(sentences, change_points)\n",
    "        \n",
    "        # Check if the blocks have changed\n",
    "        if new_blocks == blocks:\n",
    "            n_times_no_change += 1\n",
    "        else:\n",
    "            n_times_no_change = 0\n",
    "            blocks = new_blocks\n",
    "            \n",
    "        remaining_iterations -= 1\n",
    "        \n",
    "    print(\"Number of remaining iterations:\", remaining_iterations)\n",
    "    return blocks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a080e347580b71cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# test\n",
    "test_text = \"Sentence 1 talks about sentences and talks about about. While the penguin penguin while, sings the penguin while while while. A sardinian sardin Sardinian.\"\n",
    "blocks = text_tiling(test_text, 3, 5)\n",
    "\n",
    "for i, block in enumerate(blocks):\n",
    "    print(f\"Block {i+1}:\")\n",
    "    for sentence in block.sentences:\n",
    "        print(sentence)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-08T10:20:44.424367Z"
    }
   },
   "id": "a93feb0ee7c6c9a6",
   "execution_count": 0
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
