{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "We will implement a text tiling algorithm to segment the text into coherent sections. The algorithm is based on the following steps:\n",
    "1. Split the text in sentences\n",
    "2. Clean the sentences by removing stopwords and punctuation\n",
    "3. Find frequency table for the words in the sentences\n",
    "    - The x-axis is the sentence number\n",
    "    - The y-axis is each word\n",
    "    - Each cell is the frequency of the word in the sentence\n",
    "4. Initialize blocks of text with a fixed size\n",
    "5. Iterate until no change in the blocks\n",
    "    - Calculate the intra-group cohesion for each block\n",
    "    - Find blocks of text where the topic changes (the cohesion drops in these blocks)\n",
    "    - Move block boundaries to the topic change points\n",
    "6. Return the blocks of text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2128fb72ea87456"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "from string import punctuation\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.631600200Z",
     "start_time": "2024-04-08T08:26:42.507599800Z"
    }
   },
   "id": "5dd6f9034c1ec2a7",
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, text: str, words: List[str]):\n",
    "        self.text = text\n",
    "        self.words = words\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.text\n",
    "    \n",
    "class Block:\n",
    "    def __init__(self, sentences: List[Sentence]):\n",
    "        self.sentences = sentences\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \" \".join([sentence.text for sentence in self.sentences])\n",
    "    \n",
    "    def get_string_sentences(self) -> List[str]:\n",
    "        return [\" \".join(sentence.words) for sentence in self.sentences]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.634601200Z",
     "start_time": "2024-04-08T08:26:42.550599800Z"
    }
   },
   "id": "ffba7c5a7aaf9b22",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# retrieve text from res/mixed_texts.txt\n",
    "with open('res/mixed_texts.txt', 'r') as file:\n",
    "    raw_text = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.634601200Z",
     "start_time": "2024-04-08T08:26:42.571599800Z"
    }
   },
   "id": "ea8ccdbbb0b10862",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[In order to get to punch his badge at 08:30, 16 years before Fantozzi began setting alarm clock at 06:15.,\n Today, after continuous experiments and improvements, he manage to set it at 07:51: the limit of humanly possibilities.,\n Everything is calculated on the edge of seconds: 5 seconds to regain consciousness; 4 seconds to overcome impact of seeing his wife, and 6 more seconds to ask himself -as always with any plausible answer- whatever pushed him to marry that kind of curious pet; 3 seconds to drink Mrs Fantozzi's coffee: 3000 Fahreneit Degrees!,\n From 8 to 10 seconds to cool down his burned tongue... 2.5 seconds to kiss his daughter Mariangela; brioche and Latte meanwhile hair brushing, brushing coffee-flavoured teeth with minty toothpaste, resulting in an instantaneous bowel movement... all of this performed in 6 seconds, a European Record!,\n He still has a 3-minute fortune to get dressed and run to the bus stop to catch the 08:01 bus.]"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> List[Sentence]:\n",
    "    \"\"\"\n",
    "    Preprocess the text by splitting it into sentences and removing unimportant words.\n",
    "    :param text: the text to be preprocessed\n",
    "    :return: a list of relevant words extracted from text\n",
    "    \"\"\"\n",
    "    # get the list of stopwords\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    \n",
    "    sentence_list: List[Sentence] = []\n",
    "\n",
    "    # split the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # remove stopwords and punctuation\n",
    "    for sentence in sentences:\n",
    "        relevant_words = [word.lower() for word in nltk.word_tokenize(sentence) if word.lower() not in stopwords_list and word not in punctuation]\n",
    "        sentence_list.append(Sentence(sentence, relevant_words))\n",
    "        \n",
    "    return sentence_list\n",
    "\n",
    "preprocess_text(raw_text)[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.667602300Z",
     "start_time": "2024-04-08T08:26:42.590032400Z"
    }
   },
   "id": "d4fb0e2b6091c421",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # create a frequency table for the words in the sentences\n",
    "# frequency_table = []\n",
    "# \n",
    "# for sentence in cleaned_sentences:\n",
    "#     # get counts of word frequency in the sentence\n",
    "#     frequency = Counter(sentence)\n",
    "#     frequency_table.append(frequency)\n",
    "#     \n",
    "# # print the frequency table for the first 5 sentences\n",
    "# frequency_table[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.668607100Z",
     "start_time": "2024-04-08T08:26:42.617599400Z"
    }
   },
   "id": "74007fabc282ffa8",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def initialize_blocks(sentences: List[Sentence], num_blocks: int) -> List[Block]:\n",
    "    \"\"\"\n",
    "    Initialize blocks of text with a fixed size. Each block will contain a subset of the text.\n",
    "    :param sentences: the list of sentences to be split into blocks\n",
    "    :param num_blocks: the number of blocks to initialize\n",
    "    :return: a list of blocks of text\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    block_size = len(sentences) // num_blocks\n",
    "    \n",
    "    for i in range(num_blocks):\n",
    "        start = i * block_size\n",
    "        end = (i + 1) * block_size\n",
    "        block = Block(sentences[start:end])\n",
    "        blocks.append(block)\n",
    "        \n",
    "    return blocks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.669599500Z",
     "start_time": "2024-04-08T08:26:42.633599Z"
    }
   },
   "id": "531ef585d4d1f02",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# sentences = preprocess_text(raw_text)\n",
    "# blocks = initialize_blocks(sentences, 3)\n",
    "# for i, block in enumerate(blocks):\n",
    "#     print(f\"Block {i+1}:\")\n",
    "#     for sentence in block:\n",
    "#         print(sentence)\n",
    "#     print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.721600300Z",
     "start_time": "2024-04-08T08:26:42.649599900Z"
    }
   },
   "id": "84eed9b69533d3be"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_intra_group_cohesion(sentences: List[Sentence]) -> List[float]:\n",
    "\n",
    "    # TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([\" \".join(sentence.words) for sentence in sentences])\n",
    "\n",
    "    # Calculate cosine similarity between adjacent sentences\n",
    "    cohesion_scores = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        sim_score = cosine_similarity(tfidf_matrix[i], tfidf_matrix[i+1])\n",
    "        cohesion_scores.append(sim_score[0][0])\n",
    "    \n",
    "    return cohesion_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.738602200Z",
     "start_time": "2024-04-08T08:26:42.665604700Z"
    }
   },
   "id": "200db4fe52615fdc",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intra-document cohesion score: [0.0, 0.4179779031144455]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"This is a sample text. It demonstrates how to calculate intra-document cohesion between sentences. Intra-document cohesion is important for understanding the coherence of a document.\"\n",
    "sentences = preprocess_text(text)\n",
    "cohesion_score = calculate_intra_group_cohesion(sentences)\n",
    "print(\"Intra-document cohesion score:\", cohesion_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.740605Z",
     "start_time": "2024-04-08T08:26:42.678601300Z"
    }
   },
   "id": "bbca333e34113950"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "# def find_topic_change_points(cohesion_scores: List[float], num_blocks: int) -> List[int]:\n",
    "#     change_points: List[int] = []\n",
    "#     for i in range(1, len(cohesion_scores) - 1):\n",
    "#     # Check if the cohesion score is significantly lower than the previous and next scores with respect to the others\n",
    "#     pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.740605Z",
     "start_time": "2024-04-08T08:26:42.693599700Z"
    }
   },
   "id": "b796c13d03c5878f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def text_tiling(text: str, num_blocks: int, max_block_size: int) -> List[Block]:\n",
    "    \"\"\"\n",
    "    Segment the text into coherent sections using the text tiling algorithm.\n",
    "    1. Preprocess the text so that we have a list of Sentence objects\n",
    "    2. Initialize Blocks with a fixed size\n",
    "    3. Iterate until no change in the Blocks\n",
    "        - Calculate the intra-block cohesion for each Sentence\n",
    "        - Find Sentences where the topic changes (the cohesion is lower than the one of the adjacent Sentences)\n",
    "        - Move Block boundaries to the topic change points\n",
    "    4. Return the Blocks\n",
    "    :param text: the text to be segmented\n",
    "    :param num_blocks: the number of Blocks to split the text into\n",
    "    :param max_block_size: the maximum number of Sentences in each Block\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocess the text\n",
    "    sentences: List[Sentence] = preprocess_text(text)\n",
    "    \n",
    "    # Initialize blocks of text\n",
    "    blocks: List[Block] = initialize_blocks(sentences, num_blocks)\n",
    "    \n",
    "    n_times_no_change = 0\n",
    "    # Iterate until no change in the blocks\n",
    "    while n_times_no_change < 3:\n",
    "        # Calculate the intra-group cohesion for each block\n",
    "        \n",
    "        cohesion_scores: List[float] = calculate_intra_group_cohesion(sentences)\n",
    "        print(cohesion_scores)\n",
    "        \n",
    "        # for block in blocks:\n",
    "        #     # Calculate the cohesion score for the block\n",
    "        #     block_cohesion_scores = calculate_intra_group_cohesion(block)\n",
    "        #     print(block_cohesion_scores)\n",
    "        #     cohesion_scores = cohesion_scores + block_cohesion_scores\n",
    "        \n",
    "        break\n",
    "        # Find blocks of text where the topic changes\n",
    "        change_points = find_topic_change_points(cohesion_scores, num_blocks)\n",
    "        \n",
    "        # Move block boundaries to the topic change points\n",
    "        new_blocks = move_block_boundaries(blocks, change_points, max_block_size)\n",
    "        \n",
    "        # Check if the blocks have changed\n",
    "        if new_blocks == blocks:\n",
    "            n_times_no_change += 1\n",
    "        else:\n",
    "            n_times_no_change = 0\n",
    "            blocks = new_blocks\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.741610300Z",
     "start_time": "2024-04-08T08:26:42.710599200Z"
    }
   },
   "id": "a93feb0ee7c6c9a6",
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.31817326075898134, 0.0, 0.0, 0.0, 0.14081846102026818, 0.12702427781346548, 0.14269649423586434, 0.048511852537602, 0.0, 0.07149719577559598, 0.062233261308889676, 0.0, 0.02882506037503301, 0.11078810728481499, 0.17208912992558284, 0.0, 0.234892764271306, 0.0, 0.18945853708402915, 0.06987537464447131, 0.07546109793621682]\n"
     ]
    }
   ],
   "source": [
    "text_tiling(raw_text, 3, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:26:42.835599600Z",
     "start_time": "2024-04-08T08:26:42.725599700Z"
    }
   },
   "id": "be8ec6ccc2daad64"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
